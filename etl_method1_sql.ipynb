{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1cc03-8dc1-451c-a372-1f3872a5749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce40625-6840-41d7-842d-850e1c706fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").config(\"spark.executor.cores\", 8).getOrCreate()\n",
    "\n",
    "def category_AppName(df):\n",
    "    df = df.withColumn(\"Type\", when(col(\"AppName\")==\"CHANNEL\",\"Truyen hinh\")\n",
    "                       .when(col(\"AppName\")==\"RELAX\", \"Giai Tri\")\n",
    "                       .when(col(\"AppName\")==\"CHILD\", \"Thieu Nhi\")\n",
    "                       .when((col(\"AppName\")==\"FIMS\")|(col(\"AppName\")==\"VOD\"), \"Phim Truyen\")\n",
    "                       .when((col(\"AppName\")==\"KPLUS\")|(col(\"AppName\")==\"SPORT\"), \"The Thao\")\n",
    "                      )\n",
    "    df = df.select('Contract', 'Type', 'TotalDuration')\n",
    "    df = df.filter(df.Type != 'Error')\n",
    "    df = df.filter(df.Contract != '0')\n",
    "    return df\n",
    "\n",
    "def most_watch(df):\n",
    "    df=df.withColumn(\"MostWacth\",greatest(col(\"Giai Tri\"),col(\"Phim Truyen\"),col(\"The Thao\"),col(\"Thieu Nhi\"),col(\"Truyen Hinh\")))\n",
    "    df=df.withColumn(\"MostWacth\",\n",
    "                    when(col(\"MostWacth\")==col(\"Truyen Hinh\"),\"Truyen Hinh\")\n",
    "                    .when(col(\"MostWacth\")==col(\"Phim Truyen\"),\"Phim Truyen\")\n",
    "                    .when(col(\"MostWacth\")==col(\"The Thao\"),\"The Thao\")\n",
    "                    .when(col(\"MostWacth\")==col(\"Thieu Nhi\"),\"Thieu Nhi\")\n",
    "                    .when(col(\"MostWacth\")==col(\"Giai Tri\"),\"Giai Tri\"))\n",
    "    return df\n",
    "\n",
    "def customer_taste(df):\n",
    "    df = df.withColumn(\"Taste\", concat_ws(\"-\",\n",
    "                                          when(col(\"Giai Tri\").isNotNull(), lit(\"Giai Tri\")),\n",
    "                                          when(col(\"Phim truyen\").isNotNull(), lit(\"Phim truyen\")),\n",
    "                                          when(col(\"The Thao\").isNotNull(), lit(\"The Thao\")),\n",
    "                                          when(col(\"Thieu Nhi\").isNotNull(), lit(\"Thieu Nhi\")),\n",
    "                                          when(col(\"Truyen Hinh\").isNotNull(), lit(\"Truyen Hinh\"))))\n",
    "    return df\n",
    "\n",
    "def convert_to_datevalue(string):\n",
    "    date_value = datetime.strptime(string, \"%Y%m%d\").date()\n",
    "    return date_value\n",
    "\n",
    "def convert_to_stringvalue(date):\n",
    "    string_value = date.strftime(\"%Y%m%d\")\n",
    "    return string_value\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    date_list = []\n",
    "    current_date = start_date\n",
    "    while(current_date <= end_date):\n",
    "        date_list.append(convert_to_stringvalue(current_date))\n",
    "        current_date += timedelta(days=1)\n",
    "    return date_list\n",
    "\n",
    "def generate_range_date(start_date, end_date):\n",
    "    start_date = convert_to_datevalue(start_date)\n",
    "    end_date = convert_to_datevalue(end_date)\n",
    "    date_list = date_range(start_date, end_date)\n",
    "    return date_list\n",
    "\n",
    "def ETL_1_DAY(path, path_day):\n",
    "    print('------------------------')\n",
    "    print('Read data from Json file')\n",
    "    print('------------------------')\n",
    "    df = spark.read.json(path+path_day+\".json\")\n",
    "    print('------------------------')\n",
    "    print('Category AppName')\n",
    "    print('------------------------')\n",
    "    df = df.select(\"_source.*\")\n",
    "    df = category_AppName(df)\n",
    "    print('------------------------')\n",
    "    print('Pivoting data')\n",
    "    print('------------------------')\n",
    "    df = df.groupBy(\"Contract\").pivot(\"Type\").sum(\"TotalDuration\")\n",
    "    print('------------------------')\n",
    "    print('Find most watch')\n",
    "    print('------------------------')\n",
    "    df = most_watch(df)\n",
    "    print('------------------------')\n",
    "    print('Find customer taste')\n",
    "    print('------------------------')\n",
    "    df = customer_taste(df)\n",
    "    df = df.withColumn(\"Date\", to_date(lit(path_day), \"yyyyMMdd\"))\n",
    "    print('------------------------')\n",
    "    return df\n",
    "\n",
    "def import_to_postgresql(result):\n",
    "    url = 'jdbc:postgresql://' + 'localhost' + ':' + '5432' + '/' + 'test_etl'\n",
    "    driver = \"org.postgresql.Driver\"\n",
    "    user = 'postgres'\n",
    "    password = ''\n",
    "    result.write.format('jdbc').option('url', url).option('driver', driver).option('dbtable', 'customer_statistic').option('user', user).option('password', password).mode('append').save()\n",
    "    return print(\"Data import successfully\")\n",
    "\n",
    "def main(path, save_path):\n",
    "    dir_list = os.listdir(path)\n",
    "    start_date = input(\"Nhap ngay bat dau: \")\n",
    "    end_date = input(\"Nhap ngay ket thuc: \")\n",
    "    date_list = generate_range_date(start_date, end_date)\n",
    "    # print(\"ETL data file: \" + date_list[0]+\".json\")\n",
    "    result = ETL_1_DAY(path, date_list[0])\n",
    "\n",
    "    for x in date_list:\n",
    "        for y in dir_list:\n",
    "            if y == dir_list[0]:\n",
    "                continue\n",
    "            if x in y:\n",
    "                print(\"ETL data file: \" +y)\n",
    "                result = result.union(ETL_1_DAY(path, x))\n",
    "    print('-----------------------------')\n",
    "    print('Showing data')\n",
    "    print('-----------------------------') \n",
    "    result.show(10)\n",
    "    print('-----------------------------')\n",
    "    print('Saving csv output')\n",
    "    print('-----------------------------')\n",
    "    #result.repartition(1).write.csv(save_path, mode='overwrite', header=True)\n",
    "    print('-----------------------------')\n",
    "    print('Import result to mysql')\n",
    "    print('-----------------------------')\n",
    "    import_to_postgresql(result)\n",
    "    print(\"Finished job\")\n",
    "    return result\n",
    "    \n",
    "\n",
    "path = \"D:/study_de/dataset/log_content/\"\n",
    "save_path = \"D:/study_de/dataset/output_2\"\n",
    "df = main(path,save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
